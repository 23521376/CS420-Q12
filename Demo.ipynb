{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7513b63-8fec-4d6c-a7fe-daaff3ab6a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n",
      "NVIDIA GeForce RTX 3050 6GB Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "if torch.cuda.is_available():\n",
    "    print(torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "830c15a6-e01a-4e1d-9e69-59bed1818e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ROG\\Vision\\venv311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "üöÄ EfficientNet model loaded and ready!\n",
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "Could not create share link. Please check your internet connection or our status page: https://status.gradio.app.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from facenet_pytorch import MTCNN\n",
    "from torchvision import transforms, models\n",
    "\n",
    "# ------------------------------\n",
    "# DEVICE (GPU if available)\n",
    "# ------------------------------\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# ------------------------------\n",
    "# MTCNN FACE DETECTOR (SINGLE FACE, GPU)\n",
    "# ------------------------------\n",
    "# smaller detection size for speed\n",
    "mtcnn = MTCNN(keep_all=False, device=device, image_size=160, margin=20)\n",
    "\n",
    "def detect_and_crop_face(image: Image.Image, padding_ratio=0.15):\n",
    "    \"\"\"\n",
    "    Detect a single face with MTCNN and crop it.\n",
    "    \"\"\"\n",
    "    # Resize image smaller for faster detection\n",
    "    small_image = image.resize((320, 320))\n",
    "    boxes, probs = mtcnn.detect(small_image)\n",
    "\n",
    "    if boxes is None or len(boxes) == 0:\n",
    "        return None\n",
    "\n",
    "    # Only one box because keep_all=False\n",
    "    x1, y1, x2, y2 = boxes[0]\n",
    "\n",
    "    # Scale back to original image\n",
    "    scale_x = image.width / 320\n",
    "    scale_y = image.height / 320\n",
    "    x1, y1, x2, y2 = x1 * scale_x, y1 * scale_y, x2 * scale_x, y2 * scale_y\n",
    "\n",
    "    # Add padding\n",
    "    w, h = x2 - x1, y2 - y1\n",
    "    pad = padding_ratio * max(w, h)\n",
    "    x1_p = max(0, int(x1 - pad))\n",
    "    y1_p = max(0, int(y1 - pad))\n",
    "    x2_p = min(image.width, int(x2 + pad))\n",
    "    y2_p = min(image.height, int(y2 + pad))\n",
    "\n",
    "    # Crop face\n",
    "    face = image.crop((x1_p, y1_p, x2_p, y2_p))\n",
    "    return face\n",
    "\n",
    "# ------------------------------\n",
    "# LOAD EFFICIENTNET AGE MODEL\n",
    "# ------------------------------\n",
    "weights = models.EfficientNet_B0_Weights.IMAGENET1K_V1\n",
    "model_ft = models.efficientnet_b0(weights=weights)\n",
    "\n",
    "# Freeze parameters except last few layers\n",
    "for param in model_ft.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model_ft.features[-4:].parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "in_features = model_ft.classifier[1].in_features\n",
    "model_ft.classifier = nn.Sequential(\n",
    "    nn.Dropout(0.3),\n",
    "    nn.Linear(in_features, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(512, 5)\n",
    ")\n",
    "\n",
    "# Load trained model\n",
    "state_dict = torch.load(\"C:/Users/ROG/Vision/outputs/B0/best_model_64.pt\", map_location=device)\n",
    "model_ft.load_state_dict(state_dict)\n",
    "model_ft.to(device)\n",
    "model_ft.eval()\n",
    "\n",
    "# Half precision for GPU speed-up\n",
    "if device == \"cuda\":\n",
    "    model_ft.half()\n",
    "\n",
    "print(\"üöÄ EfficientNet model loaded and ready!\")\n",
    "\n",
    "# ------------------------------\n",
    "# IMAGE TRANSFORM\n",
    "# ------------------------------\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "age_groups = ['Ng∆∞·ªùi l·ªõn tu·ªïi', 'Thanh ni√™n', 'Thi·∫øu ni√™n', 'Trung ni√™n', 'Tr·∫ª em']\n",
    "\n",
    "# ------------------------------\n",
    "# PREDICTION FUNCTION\n",
    "# ------------------------------\n",
    "def predict(image: Image.Image):\n",
    "    face = detect_and_crop_face(image)\n",
    "    if face is None:\n",
    "        raise gr.Error(\"‚ùå Kh√¥ng t√¨m th·∫•y khu√¥n m·∫∑t. H√£y ch·ªçn ·∫£nh kh√°c!\")\n",
    "\n",
    "    # Transform and move to device\n",
    "    img = transform(face).unsqueeze(0).to(device)\n",
    "    if device == \"cuda\":\n",
    "        img = img.half()  # match model precision\n",
    "\n",
    "    # Inference\n",
    "    with torch.no_grad():\n",
    "        logits = model_ft(img)\n",
    "        probs = torch.softmax(logits, dim=1)[0]\n",
    "\n",
    "    return face, {age_groups[i]: float(probs[i]) for i in range(5)}\n",
    "\n",
    "# ------------------------------\n",
    "# GRADIO INTERFACE\n",
    "# ------------------------------\n",
    "gr.Interface(\n",
    "    fn=predict,\n",
    "    inputs=gr.Image(type=\"pil\", label=\"Upload Image\"),\n",
    "    outputs=[\n",
    "        gr.Image(type=\"pil\", label=\"Cropped Face\"),\n",
    "        gr.Label(num_top_classes=5, label=\"Age Prediction\")\n",
    "    ],\n",
    "    title=\"Age Classifier ‚Äì MTCNN + EfficientNet (Optimized)\",\n",
    "    description=\"Detect only faces using MTCNN (GPU if available), crop them, and predict age group using EfficientNet.\"\n",
    ").launch(share=True, inbrowser=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e265cf92-b4f0-4fc7-a3c3-acddbf020a12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ca010b-c6ed-4ff5-a3e0-838f4bab6946",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (venv311)",
   "language": "python",
   "name": "venv311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
